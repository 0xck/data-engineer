{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StringType}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql.functions.{current_timestamp, udf, when, window}\n",
    "import org.apache.spark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println (s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val inputStreamPath = \"/home/jovyan/data/events-stream\"\n",
    "val modelPath = \"/home/jovyan/models/spark-ml-model\"\n",
    "\n",
    "val dataSchema = new StructType ()\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val inputDF = spark\n",
    "    .readStream\n",
    "    .schema (dataSchema)\n",
    "    .option (\"maxFilesPerTrigger\", 1)\n",
    "    .json (inputStreamPath)\n",
    "    .withColumn (\"load_dttm\", current_timestamp ())\n",
    "\n",
    "val model = PipelineModel.load (modelPath)\n",
    "\n",
    "val getProbability = udf ((prediction : org.apache.spark.ml.linalg.Vector) => prediction (1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val predictionsDF = model.transform (inputDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative tweets probablilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictionsDF\n",
    "    .select(\n",
    "        $\"tweet\",\n",
    "        getProbability ($\"probability\") as (\"negative_probability\"))\n",
    "    .writeStream\n",
    "    .foreachBatch {\n",
    "        (batchDF : DataFrame, batchId : Long) =>\n",
    "            batchDF.show ()\n",
    "}.start ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets prediction statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionsDF\n",
    "    .select (\"prediction\", \"tweet\", \"load_dttm\")\n",
    "    .writeStream\n",
    "    .foreachBatch {\n",
    "        (batchDF : DataFrame, batchId : Long) =>\n",
    "            batchDF\n",
    "                .withWatermark (\"load_dttm\", \"10 seconds\")\n",
    "                .groupBy (window ($\"load_dttm\", \"10 seconds\") as \"time_interval\", $\"prediction\")\n",
    "                .count ()\n",
    "                .select (when ($\"prediction\" === 0, \"Positive\").otherwise (\"Negative\") as \"tweet_tone\",\n",
    "                    $\"count\",\n",
    "                    $\"time_interval\")\n",
    "                .show ()\n",
    "}.start ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
